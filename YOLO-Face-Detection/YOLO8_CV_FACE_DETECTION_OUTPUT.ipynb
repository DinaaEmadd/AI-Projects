{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c613c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8675c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 faces, 438.1ms\n",
      "Speed: 8.1ms preprocess, 438.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 453.1ms\n",
      "Speed: 8.2ms preprocess, 453.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 414.6ms\n",
      "Speed: 9.7ms preprocess, 414.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 400.5ms\n",
      "Speed: 6.0ms preprocess, 400.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 447.1ms\n",
      "Speed: 4.5ms preprocess, 447.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 407.6ms\n",
      "Speed: 5.5ms preprocess, 407.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 401.1ms\n",
      "Speed: 5.5ms preprocess, 401.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 398.2ms\n",
      "Speed: 5.3ms preprocess, 398.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 399.8ms\n",
      "Speed: 5.4ms preprocess, 399.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 417.2ms\n",
      "Speed: 5.1ms preprocess, 417.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 413.7ms\n",
      "Speed: 5.4ms preprocess, 413.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 411.7ms\n",
      "Speed: 5.5ms preprocess, 411.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 393.7ms\n",
      "Speed: 6.2ms preprocess, 393.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 395.0ms\n",
      "Speed: 5.5ms preprocess, 395.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 397.6ms\n",
      "Speed: 5.4ms preprocess, 397.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 394.7ms\n",
      "Speed: 5.5ms preprocess, 394.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 395.0ms\n",
      "Speed: 5.0ms preprocess, 395.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 399.6ms\n",
      "Speed: 5.3ms preprocess, 399.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 389.5ms\n",
      "Speed: 5.2ms preprocess, 389.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 407.5ms\n",
      "Speed: 5.4ms preprocess, 407.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 402.5ms\n",
      "Speed: 7.5ms preprocess, 402.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 435.6ms\n",
      "Speed: 7.7ms preprocess, 435.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 376.5ms\n",
      "Speed: 4.9ms preprocess, 376.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 416.2ms\n",
      "Speed: 3.8ms preprocess, 416.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 384.6ms\n",
      "Speed: 5.0ms preprocess, 384.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 436.4ms\n",
      "Speed: 5.6ms preprocess, 436.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 366.9ms\n",
      "Speed: 5.5ms preprocess, 366.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 390.9ms\n",
      "Speed: 4.3ms preprocess, 390.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 422.2ms\n",
      "Speed: 4.8ms preprocess, 422.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 432.5ms\n",
      "Speed: 4.9ms preprocess, 432.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 429.9ms\n",
      "Speed: 5.6ms preprocess, 429.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 378.7ms\n",
      "Speed: 6.2ms preprocess, 378.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 402.6ms\n",
      "Speed: 5.0ms preprocess, 402.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 350.6ms\n",
      "Speed: 5.8ms preprocess, 350.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 412.4ms\n",
      "Speed: 5.4ms preprocess, 412.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 400.9ms\n",
      "Speed: 5.1ms preprocess, 400.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 404.7ms\n",
      "Speed: 5.1ms preprocess, 404.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 345.2ms\n",
      "Speed: 5.5ms preprocess, 345.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 396.8ms\n",
      "Speed: 5.0ms preprocess, 396.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 421.4ms\n",
      "Speed: 6.7ms preprocess, 421.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 401.6ms\n",
      "Speed: 4.7ms preprocess, 401.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 398.9ms\n",
      "Speed: 5.0ms preprocess, 398.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 393.6ms\n",
      "Speed: 5.1ms preprocess, 393.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 405.1ms\n",
      "Speed: 5.3ms preprocess, 405.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 396.6ms\n",
      "Speed: 5.0ms preprocess, 396.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 398.0ms\n",
      "Speed: 5.0ms preprocess, 398.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 393.7ms\n",
      "Speed: 4.9ms preprocess, 393.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 421.5ms\n",
      "Speed: 5.1ms preprocess, 421.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 396.1ms\n",
      "Speed: 5.5ms preprocess, 396.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 403.4ms\n",
      "Speed: 5.2ms preprocess, 403.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 436.0ms\n",
      "Speed: 4.8ms preprocess, 436.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 427.8ms\n",
      "Speed: 6.8ms preprocess, 427.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 385.6ms\n",
      "Speed: 4.4ms preprocess, 385.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Video frame is empty or video processing has been successfully completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the model (make sure to use the appropriate device)\n",
    "model = YOLO('C:/Users/hp/Downloads/best (1).pt')  # Load model\n",
    "model.to(device)  # Move the model to GPU (if available)\n",
    "\n",
    "names = model.model.names\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:/Users/hp/Downloads/FACE_CV1.mp4\")\n",
    "\n",
    "frame_skip = 8 # Number of frames to skip\n",
    "frame_count = 0  # Counter to skip frames\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Skip frames to improve speed\n",
    "    if frame_count % frame_skip == 0:\n",
    "        annotator = Annotator(frame, line_width=2, font_size=2)\n",
    "        \n",
    "        # Perform object tracking or detection\n",
    "        results = model.track(frame, iou=0.5, show=False, tracker=\"bytetrack.yaml\", persist=True)\n",
    "\n",
    "        if results[0].boxes.id is not None:\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "            clss = results[0].boxes.cls.int().cpu().tolist()\n",
    "            boxes = results[0].boxes.xyxy.cpu()\n",
    "            conf = results[0].boxes.conf.tolist()\n",
    "\n",
    "            for box, track_id, cof, c in zip(boxes, track_ids, conf, clss):\n",
    "                x1, y1, x2, y2 = box.int().tolist()\n",
    "                annotator.box_label(box, label=str(names[c]), color=(255, 0, 0))\n",
    "                annotator.text(xy=(x2, y1), text=f'ID: {track_id}', box_style=True, txt_color=(255, 0, 0))\n",
    "\n",
    "                # Optional label\n",
    "                cv2.putText(frame, str(names[c]), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5, (104, 31, 17), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Optionally, avoid using cv2.imshow in production or use a different thread for display\n",
    "        cv2.imshow('img', frame)\n",
    "\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909b861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
